global {

    train_corpus="/usr1/home/wammar/parallel/swahili/all-train.sw-en"
    tune_corpus="/usr1/home/wammar/parallel/swahili/dev.sw-en"
    test_corpus="/usr1/home/wammar/parallel/swahili/test.sw-en"
    src_brown_clusters="/usr0/home/wammar/git/brown-cluster/swahili-c80-p1.out/paths"
    tgt_brown_clusters="/usr1/home/wammar/parallel/english/news-commentary10.cz-en.en.tok.brown80"

    # only specify when you want to reuse a previously built LM 
    language_model="/usr2/home/austinma/Systems/dede-enus-wmt14/ducttape/CompileLanguageModel/Corpus.cleaner/language_model"
    # only use these two parameters if you want to build a language model. if you have a language model already built, specify "language_model=" instead
    lm_order=4
    lm_data="" # /usr1/home/wammar/monolingual/lm-for-wmt11-czen/text
    
    # tool paths
    cdec_dir="/home/wammar/cdec/"
    multeval="/home/wammar/git/multeval/multeval.sh"
    giza_bin="/opt/tools/mgizapp-0.7.2/bin"
    moses_train_script="/home/wammar/git/mosesdecoder/scripts/training/train-model.perl"
    mkcls_bin="/mal0/tools/mosesdecoder/bin/mkcls"
    wammar_utils_dir="/home/wammar/wammar-utils"
    alignment_with_openfst_dir="/home/wammar/alignment-with-openfst/"
    kenlm_dir="/home/wammar/git/kenlm"

    # aer
    conv_pharaoh_script="/home/wammar/alignment-with-openfst/data/hansards/conv-pharaoh.pl"
    aer_eval_script=""
    gold_alignment=""

    # other aligner outputs
    fwd_giza_alignments=""
    bwd_giza_alignments=""
    sym_giza_alignments=""
    fwd_fast_alignments=""
    bwd_fast_alignments=""
    sym_fast_alignments=""
}
